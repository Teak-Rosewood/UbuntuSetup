{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os \n",
    "os.environ['TF_CPP_MIN_LOG_LEVEL'] = '3'\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Input,LSTM,Dense, GRU\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Configuration\n",
    "\n",
    "batch_size=256\n",
    "epochs=100\n",
    "latent_dim=64\n",
    "num_samples=900\n",
    "data_path = \"data/hindi.txt\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of samples: 900\n",
      "Number of unique input tokens: 67\n",
      "Number of unique output tokens: 77\n",
      "Max sequence length for inputs: 25\n",
      "Max sequence length for outputs: 60\n"
     ]
    }
   ],
   "source": [
    "# Vectorize the data.\n",
    "\n",
    "input_texts = []\n",
    "target_texts = []\n",
    "input_characters = set()\n",
    "target_characters = set()\n",
    "with open(data_path, 'r', encoding='utf-8') as f:\n",
    "    lines = f.read().split('\\n')\n",
    "for line in lines[: min(num_samples, len(lines) - 1)]:\n",
    "    input_text, target_text, _ = line.split('\\t')\n",
    "    # We use \"tab\" as the \"start sequence\" character\n",
    "    # for the targets, and \"\\n\" as \"end sequence\" character.\n",
    "    target_text = '\\t' + target_text + '\\n'\n",
    "    input_texts.append(input_text)\n",
    "    target_texts.append(target_text)\n",
    "    for char in input_text:\n",
    "        if char not in input_characters:\n",
    "            input_characters.add(char)\n",
    "    for char in target_text:\n",
    "        if char not in target_characters:\n",
    "            target_characters.add(char)\n",
    "\n",
    "input_characters=sorted(list(input_characters))\n",
    "target_characters=sorted(list(target_characters))\n",
    "\n",
    "num_encoder_tokens=len(input_characters)\n",
    "num_decoder_tokens=len(target_characters)\n",
    "\n",
    "max_encoder_seq_length=max([len(txt) for txt in input_texts])\n",
    "max_decoder_seq_length=max([len(txt) for txt in target_texts])\n",
    "\n",
    "print('Number of samples:', len(input_texts))\n",
    "print('Number of unique input tokens:', num_encoder_tokens)\n",
    "print('Number of unique output tokens:', num_decoder_tokens)\n",
    "print('Max sequence length for inputs:', max_encoder_seq_length)\n",
    "print('Max sequence length for outputs:', max_decoder_seq_length)\n",
    "\n",
    "input_token_index=dict(\n",
    "    [(char,i) for i, char in enumerate(input_characters)])\n",
    "target_token_index=dict(\n",
    "[(char,i) for i, char in enumerate(target_characters)])\n",
    "\n",
    "encoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_encoder_seq_length, num_encoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_input_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "decoder_target_data = np.zeros(\n",
    "    (len(input_texts), max_decoder_seq_length, num_decoder_tokens),\n",
    "    dtype='float32')\n",
    "\n",
    "for i, (input_text, target_text) in enumerate(zip(input_texts, target_texts)):\n",
    "    for t, char in enumerate(input_text):\n",
    "        encoder_input_data[i, t, input_token_index[char]] = 1.\n",
    "    encoder_input_data[i, t + 1:, input_token_index[' ']] = 1.\n",
    "    for t, char in enumerate(target_text):\n",
    "        # decoder_target_data is ahead of decoder_input_data by one timestep\n",
    "        decoder_input_data[i, t, target_token_index[char]] = 1.\n",
    "        if t > 0:\n",
    "            # decoder_target_data will be ahead by one timestep\n",
    "            # and will not include the start character.\n",
    "            decoder_target_data[i, t - 1, target_token_index[char]] = 1.\n",
    "    decoder_input_data[i, t + 1:, target_token_index[' ']] = 1.\n",
    "    decoder_target_data[i, t:, target_token_index[' ']] = 1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = LSTM(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h, state_c = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h, state_c]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_lstm = LSTM(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _, _ = decoder_lstm(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3/3 [==============================] - 3s 256ms/step - loss: 4.1871 - accuracy: 0.4401 - val_loss: 4.0060 - val_accuracy: 0.6150\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 3.7280 - accuracy: 0.7002 - val_loss: 3.1799 - val_accuracy: 0.6214\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 2.6031 - accuracy: 0.7023 - val_loss: 2.2945 - val_accuracy: 0.6214\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.8704 - accuracy: 0.7023 - val_loss: 2.1142 - val_accuracy: 0.6214\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.7010 - accuracy: 0.7023 - val_loss: 2.0571 - val_accuracy: 0.6214\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.6370 - accuracy: 0.7023 - val_loss: 2.0194 - val_accuracy: 0.6214\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.5940 - accuracy: 0.7023 - val_loss: 1.9801 - val_accuracy: 0.6214\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.5575 - accuracy: 0.7023 - val_loss: 1.9317 - val_accuracy: 0.6214\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.5283 - accuracy: 0.7023 - val_loss: 1.9505 - val_accuracy: 0.6214\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.5242 - accuracy: 0.7023 - val_loss: 1.8756 - val_accuracy: 0.6214\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4777 - accuracy: 0.7023 - val_loss: 1.9391 - val_accuracy: 0.6214\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4976 - accuracy: 0.7023 - val_loss: 1.8443 - val_accuracy: 0.6214\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4400 - accuracy: 0.7023 - val_loss: 1.8203 - val_accuracy: 0.6214\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4632 - accuracy: 0.7023 - val_loss: 1.8056 - val_accuracy: 0.6214\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4080 - accuracy: 0.7023 - val_loss: 1.7708 - val_accuracy: 0.6214\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3915 - accuracy: 0.7023 - val_loss: 2.0536 - val_accuracy: 0.6214\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4424 - accuracy: 0.7023 - val_loss: 1.7545 - val_accuracy: 0.6214\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4281 - accuracy: 0.7023 - val_loss: 1.7712 - val_accuracy: 0.6214\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3668 - accuracy: 0.7023 - val_loss: 1.7192 - val_accuracy: 0.6214\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.3926 - accuracy: 0.7023 - val_loss: 1.8111 - val_accuracy: 0.6214\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3533 - accuracy: 0.7023 - val_loss: 1.6899 - val_accuracy: 0.6214\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3502 - accuracy: 0.7023 - val_loss: 1.8485 - val_accuracy: 0.6214\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3564 - accuracy: 0.7023 - val_loss: 1.6712 - val_accuracy: 0.6214\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3249 - accuracy: 0.7023 - val_loss: 1.7292 - val_accuracy: 0.6214\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3155 - accuracy: 0.7023 - val_loss: 1.6540 - val_accuracy: 0.6214\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3253 - accuracy: 0.7036 - val_loss: 1.7215 - val_accuracy: 0.6214\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.3059 - accuracy: 0.7052 - val_loss: 1.6373 - val_accuracy: 0.6251\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2930 - accuracy: 0.7075 - val_loss: 1.6895 - val_accuracy: 0.6251\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2928 - accuracy: 0.7075 - val_loss: 1.6244 - val_accuracy: 0.6251\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2911 - accuracy: 0.7075 - val_loss: 1.6575 - val_accuracy: 0.6251\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2757 - accuracy: 0.7075 - val_loss: 1.6126 - val_accuracy: 0.6251\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2865 - accuracy: 0.7077 - val_loss: 1.6640 - val_accuracy: 0.6251\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 1.2725 - accuracy: 0.7080 - val_loss: 1.5995 - val_accuracy: 0.6258\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2589 - accuracy: 0.7082 - val_loss: 1.6231 - val_accuracy: 0.6258\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2599 - accuracy: 0.7082 - val_loss: 1.6024 - val_accuracy: 0.6258\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2663 - accuracy: 0.7082 - val_loss: 1.6279 - val_accuracy: 0.6258\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2486 - accuracy: 0.7082 - val_loss: 1.5848 - val_accuracy: 0.6258\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2452 - accuracy: 0.7082 - val_loss: 1.6262 - val_accuracy: 0.6258\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2467 - accuracy: 0.7082 - val_loss: 1.5751 - val_accuracy: 0.6258\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2374 - accuracy: 0.7082 - val_loss: 1.6067 - val_accuracy: 0.6258\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2359 - accuracy: 0.7082 - val_loss: 1.5750 - val_accuracy: 0.6256\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2325 - accuracy: 0.7082 - val_loss: 1.5912 - val_accuracy: 0.6258\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2298 - accuracy: 0.7082 - val_loss: 1.5631 - val_accuracy: 0.6258\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2244 - accuracy: 0.7082 - val_loss: 1.5862 - val_accuracy: 0.6258\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2185 - accuracy: 0.7082 - val_loss: 1.5586 - val_accuracy: 0.6258\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2177 - accuracy: 0.7082 - val_loss: 1.5957 - val_accuracy: 0.6258\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.2266 - accuracy: 0.7082 - val_loss: 1.5598 - val_accuracy: 0.6257\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2092 - accuracy: 0.7082 - val_loss: 1.5531 - val_accuracy: 0.6257\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2080 - accuracy: 0.7082 - val_loss: 1.5763 - val_accuracy: 0.6258\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2114 - accuracy: 0.7082 - val_loss: 1.5508 - val_accuracy: 0.6248\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.2070 - accuracy: 0.7082 - val_loss: 1.5536 - val_accuracy: 0.6258\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1986 - accuracy: 0.7082 - val_loss: 1.5385 - val_accuracy: 0.6254\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1983 - accuracy: 0.7082 - val_loss: 1.5551 - val_accuracy: 0.6258\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1980 - accuracy: 0.7078 - val_loss: 1.5402 - val_accuracy: 0.6240\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1962 - accuracy: 0.7079 - val_loss: 1.5535 - val_accuracy: 0.6257\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1922 - accuracy: 0.7083 - val_loss: 1.5298 - val_accuracy: 0.6247\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1893 - accuracy: 0.7078 - val_loss: 1.5402 - val_accuracy: 0.6252\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1834 - accuracy: 0.7082 - val_loss: 1.5263 - val_accuracy: 0.6246\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1912 - accuracy: 0.7063 - val_loss: 1.5673 - val_accuracy: 0.6258\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1967 - accuracy: 0.7061 - val_loss: 1.5231 - val_accuracy: 0.6246\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1772 - accuracy: 0.7081 - val_loss: 1.5222 - val_accuracy: 0.6250\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1749 - accuracy: 0.7080 - val_loss: 1.5115 - val_accuracy: 0.6249\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1781 - accuracy: 0.7079 - val_loss: 1.5320 - val_accuracy: 0.6250\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 1.1739 - accuracy: 0.7081 - val_loss: 1.5270 - val_accuracy: 0.6175\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1776 - accuracy: 0.7059 - val_loss: 1.5184 - val_accuracy: 0.6254\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1677 - accuracy: 0.7077 - val_loss: 1.5135 - val_accuracy: 0.6235\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1651 - accuracy: 0.7075 - val_loss: 1.5078 - val_accuracy: 0.6252\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1666 - accuracy: 0.7075 - val_loss: 1.5186 - val_accuracy: 0.6221\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1626 - accuracy: 0.7076 - val_loss: 1.5263 - val_accuracy: 0.6255\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.1906 - accuracy: 0.7043 - val_loss: 1.5257 - val_accuracy: 0.6206\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1668 - accuracy: 0.7081 - val_loss: 1.4977 - val_accuracy: 0.6248\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1546 - accuracy: 0.7081 - val_loss: 1.4968 - val_accuracy: 0.6247\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1523 - accuracy: 0.7081 - val_loss: 1.4912 - val_accuracy: 0.6252\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1512 - accuracy: 0.7081 - val_loss: 1.5047 - val_accuracy: 0.6251\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1505 - accuracy: 0.7083 - val_loss: 1.4952 - val_accuracy: 0.6241\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1533 - accuracy: 0.7088 - val_loss: 1.4940 - val_accuracy: 0.6256\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1481 - accuracy: 0.7085 - val_loss: 1.5014 - val_accuracy: 0.6239\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1461 - accuracy: 0.7096 - val_loss: 1.4785 - val_accuracy: 0.6255\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1429 - accuracy: 0.7085 - val_loss: 1.5020 - val_accuracy: 0.6257\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1436 - accuracy: 0.7092 - val_loss: 1.4981 - val_accuracy: 0.6176\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1487 - accuracy: 0.7093 - val_loss: 1.4862 - val_accuracy: 0.6271\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1367 - accuracy: 0.7098 - val_loss: 1.4654 - val_accuracy: 0.6268\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1370 - accuracy: 0.7098 - val_loss: 1.4793 - val_accuracy: 0.6286\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1303 - accuracy: 0.7104 - val_loss: 1.4682 - val_accuracy: 0.6269\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1373 - accuracy: 0.7110 - val_loss: 1.5144 - val_accuracy: 0.6145\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1874 - accuracy: 0.7087 - val_loss: 1.4677 - val_accuracy: 0.6313\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1278 - accuracy: 0.7124 - val_loss: 1.4635 - val_accuracy: 0.6286\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1241 - accuracy: 0.7115 - val_loss: 1.4629 - val_accuracy: 0.6306\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1215 - accuracy: 0.7122 - val_loss: 1.4591 - val_accuracy: 0.6321\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1192 - accuracy: 0.7127 - val_loss: 1.4518 - val_accuracy: 0.6329\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 36ms/step - loss: 1.1178 - accuracy: 0.7130 - val_loss: 1.4797 - val_accuracy: 0.6296\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1228 - accuracy: 0.7135 - val_loss: 1.4559 - val_accuracy: 0.6300\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1148 - accuracy: 0.7134 - val_loss: 1.4550 - val_accuracy: 0.6361\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1153 - accuracy: 0.7162 - val_loss: 1.4405 - val_accuracy: 0.6269\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1152 - accuracy: 0.7131 - val_loss: 1.4516 - val_accuracy: 0.6369\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1093 - accuracy: 0.7162 - val_loss: 1.4422 - val_accuracy: 0.6304\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1077 - accuracy: 0.7156 - val_loss: 1.4462 - val_accuracy: 0.6398\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1097 - accuracy: 0.7188 - val_loss: 1.4756 - val_accuracy: 0.6326\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1119 - accuracy: 0.7169 - val_loss: 1.4334 - val_accuracy: 0.6344\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1000 - accuracy: 0.7163 - val_loss: 1.4431 - val_accuracy: 0.6417\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.1023 - accuracy: 0.7219 - val_loss: 1.4271 - val_accuracy: 0.6328\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.1001 - accuracy: 0.7172 - val_loss: 1.4570 - val_accuracy: 0.6369\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0936 - accuracy: 0.7197 - val_loss: 1.4200 - val_accuracy: 0.6407\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0888 - accuracy: 0.7209 - val_loss: 1.4478 - val_accuracy: 0.6355\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1043 - accuracy: 0.7205 - val_loss: 1.4352 - val_accuracy: 0.6496\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0948 - accuracy: 0.7258 - val_loss: 1.4098 - val_accuracy: 0.6356\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0850 - accuracy: 0.7199 - val_loss: 1.4262 - val_accuracy: 0.6438\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0824 - accuracy: 0.7238 - val_loss: 1.4036 - val_accuracy: 0.6368\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0789 - accuracy: 0.7215 - val_loss: 1.4090 - val_accuracy: 0.6473\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0761 - accuracy: 0.7251 - val_loss: 1.3986 - val_accuracy: 0.6353\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0780 - accuracy: 0.7216 - val_loss: 1.4108 - val_accuracy: 0.6486\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0701 - accuracy: 0.7272 - val_loss: 1.3906 - val_accuracy: 0.6418\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0735 - accuracy: 0.7266 - val_loss: 1.4325 - val_accuracy: 0.6415\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0805 - accuracy: 0.7267 - val_loss: 1.3963 - val_accuracy: 0.6617\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0627 - accuracy: 0.7332 - val_loss: 1.4052 - val_accuracy: 0.6521\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0660 - accuracy: 0.7317 - val_loss: 1.3825 - val_accuracy: 0.6461\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0562 - accuracy: 0.7312 - val_loss: 1.3856 - val_accuracy: 0.6556\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0516 - accuracy: 0.7350 - val_loss: 1.3733 - val_accuracy: 0.6462\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0547 - accuracy: 0.7307 - val_loss: 1.3892 - val_accuracy: 0.6610\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0497 - accuracy: 0.7390 - val_loss: 1.3700 - val_accuracy: 0.6469\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0477 - accuracy: 0.7344 - val_loss: 1.3853 - val_accuracy: 0.6579\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0511 - accuracy: 0.7362 - val_loss: 1.3867 - val_accuracy: 0.6717\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0710 - accuracy: 0.7385 - val_loss: 1.3698 - val_accuracy: 0.6648\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0366 - accuracy: 0.7447 - val_loss: 1.3560 - val_accuracy: 0.6617\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0327 - accuracy: 0.7420 - val_loss: 1.3621 - val_accuracy: 0.6639\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0331 - accuracy: 0.7435 - val_loss: 1.3478 - val_accuracy: 0.6635\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0281 - accuracy: 0.7437 - val_loss: 1.3563 - val_accuracy: 0.6688\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0260 - accuracy: 0.7461 - val_loss: 1.3409 - val_accuracy: 0.6646\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0244 - accuracy: 0.7455 - val_loss: 1.3535 - val_accuracy: 0.6696\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0231 - accuracy: 0.7481 - val_loss: 1.3351 - val_accuracy: 0.6723\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0206 - accuracy: 0.7500 - val_loss: 1.3477 - val_accuracy: 0.6665\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0186 - accuracy: 0.7487 - val_loss: 1.3596 - val_accuracy: 0.6740\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0166 - accuracy: 0.7537 - val_loss: 1.3234 - val_accuracy: 0.6761\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0108 - accuracy: 0.7510 - val_loss: 1.3426 - val_accuracy: 0.6733\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0086 - accuracy: 0.7531 - val_loss: 1.3184 - val_accuracy: 0.6816\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.0010 - accuracy: 0.7556 - val_loss: 1.3280 - val_accuracy: 0.6762\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9996 - accuracy: 0.7554 - val_loss: 1.3180 - val_accuracy: 0.6856\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0139 - accuracy: 0.7553 - val_loss: 1.3541 - val_accuracy: 0.6563\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0005 - accuracy: 0.7544 - val_loss: 1.3070 - val_accuracy: 0.6821\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9879 - accuracy: 0.7584 - val_loss: 1.3063 - val_accuracy: 0.6841\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9890 - accuracy: 0.7600 - val_loss: 1.3000 - val_accuracy: 0.6739\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9940 - accuracy: 0.7559 - val_loss: 1.3033 - val_accuracy: 0.6888\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9807 - accuracy: 0.7633 - val_loss: 1.2921 - val_accuracy: 0.6819\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9799 - accuracy: 0.7601 - val_loss: 1.3073 - val_accuracy: 0.6869\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9796 - accuracy: 0.7643 - val_loss: 1.2857 - val_accuracy: 0.6886\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9731 - accuracy: 0.7653 - val_loss: 1.3055 - val_accuracy: 0.6771\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9784 - accuracy: 0.7596 - val_loss: 1.2917 - val_accuracy: 0.6882\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.9698 - accuracy: 0.7668 - val_loss: 1.2840 - val_accuracy: 0.6879\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9670 - accuracy: 0.7667 - val_loss: 1.2787 - val_accuracy: 0.6845\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9695 - accuracy: 0.7624 - val_loss: 1.2753 - val_accuracy: 0.6915\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9585 - accuracy: 0.7684 - val_loss: 1.2749 - val_accuracy: 0.6863\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9568 - accuracy: 0.7668 - val_loss: 1.2736 - val_accuracy: 0.6916\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9567 - accuracy: 0.7680 - val_loss: 1.2773 - val_accuracy: 0.6860\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9517 - accuracy: 0.7668 - val_loss: 1.2561 - val_accuracy: 0.6950\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.9567 - accuracy: 0.7682 - val_loss: 1.2766 - val_accuracy: 0.6909\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9446 - accuracy: 0.7692 - val_loss: 1.2589 - val_accuracy: 0.6945\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9409 - accuracy: 0.7710 - val_loss: 1.2734 - val_accuracy: 0.6916\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9444 - accuracy: 0.7703 - val_loss: 1.2647 - val_accuracy: 0.6868\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9508 - accuracy: 0.7641 - val_loss: 1.3024 - val_accuracy: 0.6837\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0206 - accuracy: 0.7494 - val_loss: 1.2668 - val_accuracy: 0.6918\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9356 - accuracy: 0.7718 - val_loss: 1.2562 - val_accuracy: 0.6939\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9306 - accuracy: 0.7714 - val_loss: 1.2527 - val_accuracy: 0.6943\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9280 - accuracy: 0.7717 - val_loss: 1.2492 - val_accuracy: 0.6949\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9256 - accuracy: 0.7719 - val_loss: 1.2468 - val_accuracy: 0.6947\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9233 - accuracy: 0.7725 - val_loss: 1.2438 - val_accuracy: 0.6953\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9210 - accuracy: 0.7721 - val_loss: 1.2424 - val_accuracy: 0.6952\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.9187 - accuracy: 0.7729 - val_loss: 1.2356 - val_accuracy: 0.6960\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9163 - accuracy: 0.7725 - val_loss: 1.2376 - val_accuracy: 0.6955\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9155 - accuracy: 0.7728 - val_loss: 1.2312 - val_accuracy: 0.6961\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9125 - accuracy: 0.7727 - val_loss: 1.2410 - val_accuracy: 0.6933\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9126 - accuracy: 0.7729 - val_loss: 1.2262 - val_accuracy: 0.6963\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9114 - accuracy: 0.7720 - val_loss: 1.2381 - val_accuracy: 0.6932\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.9088 - accuracy: 0.7732 - val_loss: 1.2185 - val_accuracy: 0.6985\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9041 - accuracy: 0.7738 - val_loss: 1.2283 - val_accuracy: 0.6954\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9062 - accuracy: 0.7724 - val_loss: 1.2074 - val_accuracy: 0.6981\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9015 - accuracy: 0.7744 - val_loss: 1.2251 - val_accuracy: 0.6958\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9000 - accuracy: 0.7751 - val_loss: 1.2127 - val_accuracy: 0.6958\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9011 - accuracy: 0.7727 - val_loss: 1.2034 - val_accuracy: 0.6961\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8939 - accuracy: 0.7749 - val_loss: 1.2181 - val_accuracy: 0.6964\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8942 - accuracy: 0.7749 - val_loss: 1.1899 - val_accuracy: 0.7007\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8909 - accuracy: 0.7762 - val_loss: 1.2049 - val_accuracy: 0.6981\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8844 - accuracy: 0.7765 - val_loss: 1.1996 - val_accuracy: 0.6976\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8939 - accuracy: 0.7728 - val_loss: 1.1910 - val_accuracy: 0.6980\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8802 - accuracy: 0.7766 - val_loss: 1.1953 - val_accuracy: 0.7006\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8770 - accuracy: 0.7778 - val_loss: 1.1790 - val_accuracy: 0.7012\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 38ms/step - loss: 0.8863 - accuracy: 0.7762 - val_loss: 1.2642 - val_accuracy: 0.6860\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9036 - accuracy: 0.7727 - val_loss: 1.1733 - val_accuracy: 0.7026\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8716 - accuracy: 0.7787 - val_loss: 1.1712 - val_accuracy: 0.7036\n",
      "Epoch 189/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8688 - accuracy: 0.7793 - val_loss: 1.1692 - val_accuracy: 0.7034\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8665 - accuracy: 0.7792 - val_loss: 1.1720 - val_accuracy: 0.7028\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8646 - accuracy: 0.7799 - val_loss: 1.1796 - val_accuracy: 0.7036\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8657 - accuracy: 0.7801 - val_loss: 1.1708 - val_accuracy: 0.7047\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8642 - accuracy: 0.7794 - val_loss: 1.1726 - val_accuracy: 0.7037\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8632 - accuracy: 0.7814 - val_loss: 1.1659 - val_accuracy: 0.7054\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8593 - accuracy: 0.7814 - val_loss: 1.1693 - val_accuracy: 0.7044\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8575 - accuracy: 0.7822 - val_loss: 1.1618 - val_accuracy: 0.7062\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8534 - accuracy: 0.7814 - val_loss: 1.1596 - val_accuracy: 0.7022\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8627 - accuracy: 0.7806 - val_loss: 1.1650 - val_accuracy: 0.7052\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8505 - accuracy: 0.7823 - val_loss: 1.1535 - val_accuracy: 0.7062\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8469 - accuracy: 0.7824 - val_loss: 1.1637 - val_accuracy: 0.7059\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8506 - accuracy: 0.7825 - val_loss: 1.1582 - val_accuracy: 0.7069\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8462 - accuracy: 0.7828 - val_loss: 1.1432 - val_accuracy: 0.7086\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8418 - accuracy: 0.7840 - val_loss: 1.1504 - val_accuracy: 0.7081\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8423 - accuracy: 0.7829 - val_loss: 1.1623 - val_accuracy: 0.7052\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8434 - accuracy: 0.7836 - val_loss: 1.1379 - val_accuracy: 0.7081\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8409 - accuracy: 0.7833 - val_loss: 1.1842 - val_accuracy: 0.7031\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8534 - accuracy: 0.7809 - val_loss: 1.1410 - val_accuracy: 0.7082\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8318 - accuracy: 0.7851 - val_loss: 1.1408 - val_accuracy: 0.7084\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8295 - accuracy: 0.7859 - val_loss: 1.1365 - val_accuracy: 0.7087\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8284 - accuracy: 0.7855 - val_loss: 1.1440 - val_accuracy: 0.7095\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8337 - accuracy: 0.7852 - val_loss: 1.1340 - val_accuracy: 0.7108\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8275 - accuracy: 0.7851 - val_loss: 1.1359 - val_accuracy: 0.7107\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.8257 - accuracy: 0.7871 - val_loss: 1.1307 - val_accuracy: 0.7094\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8241 - accuracy: 0.7860 - val_loss: 1.1241 - val_accuracy: 0.7067\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8302 - accuracy: 0.7859 - val_loss: 1.1271 - val_accuracy: 0.7111\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8201 - accuracy: 0.7871 - val_loss: 1.1231 - val_accuracy: 0.7117\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8205 - accuracy: 0.7864 - val_loss: 1.1290 - val_accuracy: 0.7094\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8171 - accuracy: 0.7876 - val_loss: 1.1242 - val_accuracy: 0.7114\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8157 - accuracy: 0.7886 - val_loss: 1.1154 - val_accuracy: 0.7119\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8157 - accuracy: 0.7895 - val_loss: 1.1300 - val_accuracy: 0.7103\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8179 - accuracy: 0.7885 - val_loss: 1.1073 - val_accuracy: 0.7125\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8125 - accuracy: 0.7894 - val_loss: 1.1176 - val_accuracy: 0.7123\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8073 - accuracy: 0.7894 - val_loss: 1.1209 - val_accuracy: 0.7144\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8094 - accuracy: 0.7890 - val_loss: 1.1189 - val_accuracy: 0.7127\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8125 - accuracy: 0.7879 - val_loss: 1.1108 - val_accuracy: 0.7140\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8058 - accuracy: 0.7910 - val_loss: 1.1079 - val_accuracy: 0.7136\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8011 - accuracy: 0.7915 - val_loss: 1.1177 - val_accuracy: 0.7136\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8036 - accuracy: 0.7903 - val_loss: 1.0977 - val_accuracy: 0.7151\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8048 - accuracy: 0.7922 - val_loss: 1.1241 - val_accuracy: 0.7123\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8052 - accuracy: 0.7916 - val_loss: 1.0916 - val_accuracy: 0.7152\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7979 - accuracy: 0.7927 - val_loss: 1.1065 - val_accuracy: 0.7157\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7979 - accuracy: 0.7926 - val_loss: 1.1004 - val_accuracy: 0.7163\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7967 - accuracy: 0.7914 - val_loss: 1.1008 - val_accuracy: 0.7167\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7933 - accuracy: 0.7942 - val_loss: 1.0962 - val_accuracy: 0.7172\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7934 - accuracy: 0.7929 - val_loss: 1.1028 - val_accuracy: 0.7200\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7910 - accuracy: 0.7953 - val_loss: 1.0961 - val_accuracy: 0.7194\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7869 - accuracy: 0.7950 - val_loss: 1.0974 - val_accuracy: 0.7196\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7938 - accuracy: 0.7935 - val_loss: 1.1066 - val_accuracy: 0.7167\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7935 - accuracy: 0.7926 - val_loss: 1.0831 - val_accuracy: 0.7208\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7880 - accuracy: 0.7964 - val_loss: 1.0895 - val_accuracy: 0.7221\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7819 - accuracy: 0.7975 - val_loss: 1.0818 - val_accuracy: 0.7235\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7811 - accuracy: 0.7972 - val_loss: 1.0866 - val_accuracy: 0.7221\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7795 - accuracy: 0.7977 - val_loss: 1.0864 - val_accuracy: 0.7234\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7806 - accuracy: 0.7956 - val_loss: 1.0984 - val_accuracy: 0.7158\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7889 - accuracy: 0.7950 - val_loss: 1.0753 - val_accuracy: 0.7229\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7763 - accuracy: 0.7987 - val_loss: 1.0834 - val_accuracy: 0.7245\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7748 - accuracy: 0.7986 - val_loss: 1.0730 - val_accuracy: 0.7227\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7826 - accuracy: 0.7968 - val_loss: 1.0667 - val_accuracy: 0.7246\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7718 - accuracy: 0.7990 - val_loss: 1.0751 - val_accuracy: 0.7256\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7758 - accuracy: 0.7987 - val_loss: 1.0747 - val_accuracy: 0.7244\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7710 - accuracy: 0.7997 - val_loss: 1.0711 - val_accuracy: 0.7256\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7696 - accuracy: 0.8002 - val_loss: 1.0693 - val_accuracy: 0.7256\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7692 - accuracy: 0.8002 - val_loss: 1.0828 - val_accuracy: 0.7242\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7726 - accuracy: 0.7996 - val_loss: 1.0665 - val_accuracy: 0.7257\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7704 - accuracy: 0.8010 - val_loss: 1.0663 - val_accuracy: 0.7278\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7636 - accuracy: 0.8021 - val_loss: 1.0630 - val_accuracy: 0.7264\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 45ms/step - loss: 0.7669 - accuracy: 0.8003 - val_loss: 1.0678 - val_accuracy: 0.7269\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7644 - accuracy: 0.8017 - val_loss: 1.0652 - val_accuracy: 0.7266\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7607 - accuracy: 0.8015 - val_loss: 1.0623 - val_accuracy: 0.7285\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7605 - accuracy: 0.8024 - val_loss: 1.0741 - val_accuracy: 0.7250\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7667 - accuracy: 0.7996 - val_loss: 1.0552 - val_accuracy: 0.7259\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7590 - accuracy: 0.8031 - val_loss: 1.0544 - val_accuracy: 0.7291\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7570 - accuracy: 0.8036 - val_loss: 1.0509 - val_accuracy: 0.7287\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7545 - accuracy: 0.8026 - val_loss: 1.0529 - val_accuracy: 0.7301\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7520 - accuracy: 0.8042 - val_loss: 1.0440 - val_accuracy: 0.7281\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7599 - accuracy: 0.8015 - val_loss: 1.0614 - val_accuracy: 0.7269\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7564 - accuracy: 0.8030 - val_loss: 1.0584 - val_accuracy: 0.7277\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7538 - accuracy: 0.8028 - val_loss: 1.0424 - val_accuracy: 0.7297\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7513 - accuracy: 0.8045 - val_loss: 1.0505 - val_accuracy: 0.7287\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7474 - accuracy: 0.8046 - val_loss: 1.0426 - val_accuracy: 0.7301\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7478 - accuracy: 0.8056 - val_loss: 1.0458 - val_accuracy: 0.7298\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7492 - accuracy: 0.8044 - val_loss: 1.0543 - val_accuracy: 0.7264\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7510 - accuracy: 0.8041 - val_loss: 1.0327 - val_accuracy: 0.7316\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7475 - accuracy: 0.8049 - val_loss: 1.0446 - val_accuracy: 0.7295\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7421 - accuracy: 0.8059 - val_loss: 1.0437 - val_accuracy: 0.7312\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7456 - accuracy: 0.8057 - val_loss: 1.0441 - val_accuracy: 0.7290\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7415 - accuracy: 0.8055 - val_loss: 1.0326 - val_accuracy: 0.7340\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.7395 - accuracy: 0.8065 - val_loss: 1.0413 - val_accuracy: 0.7301\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7386 - accuracy: 0.8061 - val_loss: 1.0279 - val_accuracy: 0.7311\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7395 - accuracy: 0.8052 - val_loss: 1.0503 - val_accuracy: 0.7291\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7432 - accuracy: 0.8056 - val_loss: 1.0370 - val_accuracy: 0.7299\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7362 - accuracy: 0.8066 - val_loss: 1.0260 - val_accuracy: 0.7358\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.7382 - accuracy: 0.8078 - val_loss: 1.0316 - val_accuracy: 0.7319\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7329 - accuracy: 0.8073 - val_loss: 1.0287 - val_accuracy: 0.7326\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7338 - accuracy: 0.8065 - val_loss: 1.0368 - val_accuracy: 0.7319\n",
      "Epoch 286/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7389 - accuracy: 0.8066 - val_loss: 1.0243 - val_accuracy: 0.7348\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7334 - accuracy: 0.8078 - val_loss: 1.0316 - val_accuracy: 0.7334\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7283 - accuracy: 0.8094 - val_loss: 1.0202 - val_accuracy: 0.7358\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7287 - accuracy: 0.8082 - val_loss: 1.0369 - val_accuracy: 0.7328\n",
      "Epoch 290/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7316 - accuracy: 0.8082 - val_loss: 1.0178 - val_accuracy: 0.7377\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7265 - accuracy: 0.8098 - val_loss: 1.0260 - val_accuracy: 0.7344\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7260 - accuracy: 0.8094 - val_loss: 1.0203 - val_accuracy: 0.7352\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7306 - accuracy: 0.8071 - val_loss: 1.0354 - val_accuracy: 0.7331\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 0s 34ms/step - loss: 0.7255 - accuracy: 0.8090 - val_loss: 1.0151 - val_accuracy: 0.7385\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7243 - accuracy: 0.8095 - val_loss: 1.0224 - val_accuracy: 0.7340\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7256 - accuracy: 0.8092 - val_loss: 1.0235 - val_accuracy: 0.7335\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7214 - accuracy: 0.8108 - val_loss: 1.0170 - val_accuracy: 0.7357\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7227 - accuracy: 0.8104 - val_loss: 1.0239 - val_accuracy: 0.7358\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7221 - accuracy: 0.8103 - val_loss: 1.0156 - val_accuracy: 0.7355\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7210 - accuracy: 0.8106 - val_loss: 1.0244 - val_accuracy: 0.7352\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe7840dbfd0>"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "lstm = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "lstm.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "lstm_hist = lstm.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "lstm.save('lstm.keras')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define sampling models\n",
    "encoder_model = Model(encoder_inputs, encoder_states)\n",
    "\n",
    "decoder_state_input_h = Input(shape=(latent_dim,))\n",
    "decoder_state_input_c = Input(shape=(latent_dim,))\n",
    "decoder_states_inputs = [decoder_state_input_h, decoder_state_input_c]\n",
    "decoder_outputs, state_h, state_c = decoder_lstm(\n",
    "    decoder_inputs, initial_state=decoder_states_inputs)\n",
    "decoder_states = [state_h, state_c]\n",
    "decoder_outputs = decoder_dense(decoder_outputs)\n",
    "decoder_model = Model(\n",
    "    [decoder_inputs] + decoder_states_inputs,\n",
    "    [decoder_outputs] + decoder_states)\n",
    "\n",
    "# Reverse-lookup token index to decode sequences back to\n",
    "# something readable.\n",
    "reverse_input_char_index = dict(\n",
    "    (i, char) for char, i in input_token_index.items())\n",
    "reverse_target_char_index = dict(\n",
    "    (i, char) for char, i in target_token_index.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def decode_sequence(input_seq):\n",
    "    # Encode the input as state vectors.\n",
    "    states_value = encoder_model.predict(input_seq)\n",
    "\n",
    "    # Generate empty target sequence of length 1.\n",
    "    target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "    # Populate the first character of target sequence with the start character.\n",
    "    target_seq[0, 0, target_token_index['\\t']] = 1.\n",
    "\n",
    "    # Sampling loop for a batch of sequences\n",
    "    # (to simplify, here we assume a batch of size 1).\n",
    "    stop_condition = False\n",
    "    decoded_sentence = ''\n",
    "    while not stop_condition:\n",
    "        output_tokens, h, c = decoder_model.predict(([target_seq] + states_value), verbose = 0)\n",
    "\n",
    "        # Sample a token\n",
    "        sampled_token_index = np.argmax(output_tokens[0, -1, :])\n",
    "        sampled_char = reverse_target_char_index[sampled_token_index]\n",
    "        decoded_sentence += sampled_char\n",
    "\n",
    "        # Exit condition: either hit max length\n",
    "        # or find stop character.\n",
    "        if (sampled_char == '\\n' or\n",
    "           len(decoded_sentence) > max_decoder_seq_length):\n",
    "            stop_condition = True\n",
    "\n",
    "        # Update the target sequence (of length 1).\n",
    "        target_seq = np.zeros((1, 1, num_decoder_tokens))\n",
    "        target_seq[0, 0, sampled_token_index] = 1.\n",
    "\n",
    "        # Update states\n",
    "        states_value = [h, c]\n",
    "\n",
    "    return decoded_sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define an input sequence and process it.\n",
    "encoder_inputs = Input(shape=(None, num_encoder_tokens))\n",
    "encoder = GRU(latent_dim, return_state=True)\n",
    "encoder_outputs, state_h = encoder(encoder_inputs)\n",
    "# We discard `encoder_outputs` and only keep the states.\n",
    "encoder_states = [state_h]\n",
    "\n",
    "# Set up the decoder, using `encoder_states` as initial state.\n",
    "decoder_inputs = Input(shape=(None, num_decoder_tokens))\n",
    "# We set up our decoder to return full output sequences,\n",
    "# and to return internal states as well. We don't use the\n",
    "# return states in the training model, but we will use them in inference.\n",
    "decoder_gru = GRU(latent_dim, return_sequences=True, return_state=True)\n",
    "decoder_outputs, _= decoder_gru(decoder_inputs,\n",
    "                                     initial_state=encoder_states)\n",
    "decoder_dense = Dense(num_decoder_tokens, activation='softmax')\n",
    "decoder_outputs = decoder_dense(decoder_outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/300\n",
      "3/3 [==============================] - 2s 223ms/step - loss: 4.2586 - accuracy: 0.1991 - val_loss: 4.1435 - val_accuracy: 0.5955\n",
      "Epoch 2/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 4.0436 - accuracy: 0.6937 - val_loss: 3.9459 - val_accuracy: 0.6214\n",
      "Epoch 3/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.7745 - accuracy: 0.7022 - val_loss: 3.6008 - val_accuracy: 0.6214\n",
      "Epoch 4/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 3.2061 - accuracy: 0.7023 - val_loss: 2.6135 - val_accuracy: 0.6214\n",
      "Epoch 5/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.9746 - accuracy: 0.7023 - val_loss: 2.0365 - val_accuracy: 0.6214\n",
      "Epoch 6/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.6142 - accuracy: 0.7023 - val_loss: 2.0031 - val_accuracy: 0.6214\n",
      "Epoch 7/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.5721 - accuracy: 0.7023 - val_loss: 1.9681 - val_accuracy: 0.6214\n",
      "Epoch 8/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.5435 - accuracy: 0.7023 - val_loss: 1.9432 - val_accuracy: 0.6214\n",
      "Epoch 9/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.5205 - accuracy: 0.7023 - val_loss: 1.9145 - val_accuracy: 0.6214\n",
      "Epoch 10/300\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.4998 - accuracy: 0.7023 - val_loss: 1.8900 - val_accuracy: 0.6214\n",
      "Epoch 11/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.4813 - accuracy: 0.7023 - val_loss: 1.8610 - val_accuracy: 0.6214\n",
      "Epoch 12/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.4640 - accuracy: 0.7023 - val_loss: 1.8426 - val_accuracy: 0.6214\n",
      "Epoch 13/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4489 - accuracy: 0.7023 - val_loss: 1.8747 - val_accuracy: 0.6214\n",
      "Epoch 14/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4583 - accuracy: 0.7023 - val_loss: 1.8170 - val_accuracy: 0.6214\n",
      "Epoch 15/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.4407 - accuracy: 0.7023 - val_loss: 1.8318 - val_accuracy: 0.6214\n",
      "Epoch 16/300\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.4223 - accuracy: 0.7023 - val_loss: 1.7989 - val_accuracy: 0.6214\n",
      "Epoch 17/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.4219 - accuracy: 0.7023 - val_loss: 1.8227 - val_accuracy: 0.6214\n",
      "Epoch 18/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.4152 - accuracy: 0.7023 - val_loss: 1.7841 - val_accuracy: 0.6214\n",
      "Epoch 19/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.4104 - accuracy: 0.7023 - val_loss: 1.8083 - val_accuracy: 0.6214\n",
      "Epoch 20/300\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.3948 - accuracy: 0.7023 - val_loss: 1.7605 - val_accuracy: 0.6214\n",
      "Epoch 21/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3838 - accuracy: 0.7023 - val_loss: 1.7794 - val_accuracy: 0.6214\n",
      "Epoch 22/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3922 - accuracy: 0.7023 - val_loss: 1.7609 - val_accuracy: 0.6214\n",
      "Epoch 23/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3877 - accuracy: 0.7023 - val_loss: 1.7718 - val_accuracy: 0.6214\n",
      "Epoch 24/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3764 - accuracy: 0.7023 - val_loss: 1.7426 - val_accuracy: 0.6214\n",
      "Epoch 25/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3693 - accuracy: 0.7023 - val_loss: 1.7533 - val_accuracy: 0.6214\n",
      "Epoch 26/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3614 - accuracy: 0.7023 - val_loss: 1.7301 - val_accuracy: 0.6214\n",
      "Epoch 27/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3557 - accuracy: 0.7023 - val_loss: 1.7414 - val_accuracy: 0.6214\n",
      "Epoch 28/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3576 - accuracy: 0.7023 - val_loss: 1.7243 - val_accuracy: 0.6214\n",
      "Epoch 29/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3511 - accuracy: 0.7023 - val_loss: 1.7309 - val_accuracy: 0.6214\n",
      "Epoch 30/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3495 - accuracy: 0.7023 - val_loss: 1.7187 - val_accuracy: 0.6214\n",
      "Epoch 31/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3402 - accuracy: 0.7023 - val_loss: 1.7103 - val_accuracy: 0.6214\n",
      "Epoch 32/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3325 - accuracy: 0.7023 - val_loss: 1.7041 - val_accuracy: 0.6214\n",
      "Epoch 33/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3292 - accuracy: 0.7023 - val_loss: 1.7102 - val_accuracy: 0.6214\n",
      "Epoch 34/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3247 - accuracy: 0.7023 - val_loss: 1.7168 - val_accuracy: 0.6214\n",
      "Epoch 35/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3324 - accuracy: 0.7023 - val_loss: 1.6940 - val_accuracy: 0.6214\n",
      "Epoch 36/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3164 - accuracy: 0.7023 - val_loss: 1.6881 - val_accuracy: 0.6214\n",
      "Epoch 37/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3124 - accuracy: 0.7023 - val_loss: 1.6837 - val_accuracy: 0.6214\n",
      "Epoch 38/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.3082 - accuracy: 0.7023 - val_loss: 1.6891 - val_accuracy: 0.6214\n",
      "Epoch 39/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.3112 - accuracy: 0.7023 - val_loss: 1.6793 - val_accuracy: 0.6214\n",
      "Epoch 40/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 1.3091 - accuracy: 0.7023 - val_loss: 1.6684 - val_accuracy: 0.6214\n",
      "Epoch 41/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2978 - accuracy: 0.7023 - val_loss: 1.6656 - val_accuracy: 0.6214\n",
      "Epoch 42/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2945 - accuracy: 0.7023 - val_loss: 1.6695 - val_accuracy: 0.6248\n",
      "Epoch 43/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2939 - accuracy: 0.7045 - val_loss: 1.6544 - val_accuracy: 0.6243\n",
      "Epoch 44/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2856 - accuracy: 0.7051 - val_loss: 1.6605 - val_accuracy: 0.6251\n",
      "Epoch 45/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2850 - accuracy: 0.7075 - val_loss: 1.6462 - val_accuracy: 0.6251\n",
      "Epoch 46/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2774 - accuracy: 0.7075 - val_loss: 1.6401 - val_accuracy: 0.6251\n",
      "Epoch 47/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2846 - accuracy: 0.7075 - val_loss: 1.6302 - val_accuracy: 0.6251\n",
      "Epoch 48/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2621 - accuracy: 0.7075 - val_loss: 1.6307 - val_accuracy: 0.6251\n",
      "Epoch 49/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2719 - accuracy: 0.7075 - val_loss: 1.6280 - val_accuracy: 0.6251\n",
      "Epoch 50/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2649 - accuracy: 0.7075 - val_loss: 1.6310 - val_accuracy: 0.6251\n",
      "Epoch 51/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2620 - accuracy: 0.7075 - val_loss: 1.6234 - val_accuracy: 0.6251\n",
      "Epoch 52/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2604 - accuracy: 0.7075 - val_loss: 1.6182 - val_accuracy: 0.6251\n",
      "Epoch 53/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2521 - accuracy: 0.7075 - val_loss: 1.6115 - val_accuracy: 0.6251\n",
      "Epoch 54/300\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.2504 - accuracy: 0.7075 - val_loss: 1.6171 - val_accuracy: 0.6251\n",
      "Epoch 55/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2487 - accuracy: 0.7075 - val_loss: 1.6079 - val_accuracy: 0.6251\n",
      "Epoch 56/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2433 - accuracy: 0.7075 - val_loss: 1.6000 - val_accuracy: 0.6254\n",
      "Epoch 57/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2393 - accuracy: 0.7076 - val_loss: 1.6001 - val_accuracy: 0.6251\n",
      "Epoch 58/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2373 - accuracy: 0.7076 - val_loss: 1.6005 - val_accuracy: 0.6258\n",
      "Epoch 59/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2359 - accuracy: 0.7079 - val_loss: 1.5921 - val_accuracy: 0.6251\n",
      "Epoch 60/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2304 - accuracy: 0.7078 - val_loss: 1.5797 - val_accuracy: 0.6258\n",
      "Epoch 61/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2279 - accuracy: 0.7080 - val_loss: 1.5783 - val_accuracy: 0.6251\n",
      "Epoch 62/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2206 - accuracy: 0.7078 - val_loss: 1.5767 - val_accuracy: 0.6258\n",
      "Epoch 63/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2240 - accuracy: 0.7081 - val_loss: 1.5692 - val_accuracy: 0.6254\n",
      "Epoch 64/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2110 - accuracy: 0.7077 - val_loss: 1.5736 - val_accuracy: 0.6258\n",
      "Epoch 65/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.2174 - accuracy: 0.7080 - val_loss: 1.5657 - val_accuracy: 0.6256\n",
      "Epoch 66/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2093 - accuracy: 0.7078 - val_loss: 1.5578 - val_accuracy: 0.6258\n",
      "Epoch 67/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.2090 - accuracy: 0.7081 - val_loss: 1.5575 - val_accuracy: 0.6257\n",
      "Epoch 68/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1997 - accuracy: 0.7079 - val_loss: 1.5502 - val_accuracy: 0.6258\n",
      "Epoch 69/300\n",
      "3/3 [==============================] - 0s 22ms/step - loss: 1.2006 - accuracy: 0.7082 - val_loss: 1.5548 - val_accuracy: 0.6257\n",
      "Epoch 70/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1994 - accuracy: 0.7083 - val_loss: 1.5417 - val_accuracy: 0.6258\n",
      "Epoch 71/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1964 - accuracy: 0.7083 - val_loss: 1.5395 - val_accuracy: 0.6258\n",
      "Epoch 72/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1873 - accuracy: 0.7082 - val_loss: 1.5399 - val_accuracy: 0.6256\n",
      "Epoch 73/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1887 - accuracy: 0.7082 - val_loss: 1.5398 - val_accuracy: 0.6258\n",
      "Epoch 74/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1864 - accuracy: 0.7083 - val_loss: 1.5343 - val_accuracy: 0.6260\n",
      "Epoch 75/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1818 - accuracy: 0.7082 - val_loss: 1.5289 - val_accuracy: 0.6258\n",
      "Epoch 76/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1786 - accuracy: 0.7084 - val_loss: 1.5257 - val_accuracy: 0.6262\n",
      "Epoch 77/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1762 - accuracy: 0.7085 - val_loss: 1.5214 - val_accuracy: 0.6259\n",
      "Epoch 78/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1714 - accuracy: 0.7082 - val_loss: 1.5232 - val_accuracy: 0.6265\n",
      "Epoch 79/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1699 - accuracy: 0.7083 - val_loss: 1.5126 - val_accuracy: 0.6258\n",
      "Epoch 80/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1631 - accuracy: 0.7084 - val_loss: 1.5124 - val_accuracy: 0.6269\n",
      "Epoch 81/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1667 - accuracy: 0.7088 - val_loss: 1.5020 - val_accuracy: 0.6258\n",
      "Epoch 82/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 1.1559 - accuracy: 0.7085 - val_loss: 1.4998 - val_accuracy: 0.6264\n",
      "Epoch 83/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 1.1565 - accuracy: 0.7088 - val_loss: 1.4975 - val_accuracy: 0.6258\n",
      "Epoch 84/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1523 - accuracy: 0.7086 - val_loss: 1.4980 - val_accuracy: 0.6272\n",
      "Epoch 85/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1499 - accuracy: 0.7088 - val_loss: 1.4893 - val_accuracy: 0.6257\n",
      "Epoch 86/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1439 - accuracy: 0.7086 - val_loss: 1.4886 - val_accuracy: 0.6278\n",
      "Epoch 87/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1446 - accuracy: 0.7100 - val_loss: 1.4805 - val_accuracy: 0.6257\n",
      "Epoch 88/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1373 - accuracy: 0.7091 - val_loss: 1.4780 - val_accuracy: 0.6281\n",
      "Epoch 89/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1350 - accuracy: 0.7097 - val_loss: 1.4765 - val_accuracy: 0.6257\n",
      "Epoch 90/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1313 - accuracy: 0.7094 - val_loss: 1.4702 - val_accuracy: 0.6291\n",
      "Epoch 91/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1282 - accuracy: 0.7109 - val_loss: 1.4664 - val_accuracy: 0.6257\n",
      "Epoch 92/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1238 - accuracy: 0.7100 - val_loss: 1.4619 - val_accuracy: 0.6311\n",
      "Epoch 93/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1201 - accuracy: 0.7116 - val_loss: 1.4568 - val_accuracy: 0.6260\n",
      "Epoch 94/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1151 - accuracy: 0.7108 - val_loss: 1.4531 - val_accuracy: 0.6351\n",
      "Epoch 95/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1146 - accuracy: 0.7158 - val_loss: 1.4466 - val_accuracy: 0.6261\n",
      "Epoch 96/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.1078 - accuracy: 0.7124 - val_loss: 1.4449 - val_accuracy: 0.6431\n",
      "Epoch 97/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.1056 - accuracy: 0.7181 - val_loss: 1.4382 - val_accuracy: 0.6266\n",
      "Epoch 98/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0992 - accuracy: 0.7137 - val_loss: 1.4330 - val_accuracy: 0.6445\n",
      "Epoch 99/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0974 - accuracy: 0.7192 - val_loss: 1.4298 - val_accuracy: 0.6281\n",
      "Epoch 100/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0917 - accuracy: 0.7166 - val_loss: 1.4248 - val_accuracy: 0.6471\n",
      "Epoch 101/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0890 - accuracy: 0.7233 - val_loss: 1.4188 - val_accuracy: 0.6348\n",
      "Epoch 102/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0823 - accuracy: 0.7214 - val_loss: 1.4134 - val_accuracy: 0.6497\n",
      "Epoch 103/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0815 - accuracy: 0.7272 - val_loss: 1.4081 - val_accuracy: 0.6396\n",
      "Epoch 104/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0733 - accuracy: 0.7235 - val_loss: 1.4041 - val_accuracy: 0.6510\n",
      "Epoch 105/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0701 - accuracy: 0.7284 - val_loss: 1.4006 - val_accuracy: 0.6402\n",
      "Epoch 106/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0653 - accuracy: 0.7270 - val_loss: 1.3937 - val_accuracy: 0.6546\n",
      "Epoch 107/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 1.0620 - accuracy: 0.7323 - val_loss: 1.3909 - val_accuracy: 0.6417\n",
      "Epoch 108/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0567 - accuracy: 0.7291 - val_loss: 1.3788 - val_accuracy: 0.6544\n",
      "Epoch 109/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0502 - accuracy: 0.7319 - val_loss: 1.3796 - val_accuracy: 0.6433\n",
      "Epoch 110/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0473 - accuracy: 0.7327 - val_loss: 1.3688 - val_accuracy: 0.6596\n",
      "Epoch 111/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0421 - accuracy: 0.7361 - val_loss: 1.3666 - val_accuracy: 0.6469\n",
      "Epoch 112/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0369 - accuracy: 0.7335 - val_loss: 1.3577 - val_accuracy: 0.6641\n",
      "Epoch 113/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0331 - accuracy: 0.7399 - val_loss: 1.3554 - val_accuracy: 0.6516\n",
      "Epoch 114/300\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 1.0269 - accuracy: 0.7358 - val_loss: 1.3442 - val_accuracy: 0.6631\n",
      "Epoch 115/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 1.0225 - accuracy: 0.7404 - val_loss: 1.3449 - val_accuracy: 0.6533\n",
      "Epoch 116/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0196 - accuracy: 0.7402 - val_loss: 1.3358 - val_accuracy: 0.6786\n",
      "Epoch 117/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 1.0128 - accuracy: 0.7461 - val_loss: 1.3317 - val_accuracy: 0.6561\n",
      "Epoch 118/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0087 - accuracy: 0.7422 - val_loss: 1.3264 - val_accuracy: 0.6841\n",
      "Epoch 119/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 1.0047 - accuracy: 0.7505 - val_loss: 1.3201 - val_accuracy: 0.6614\n",
      "Epoch 120/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9987 - accuracy: 0.7451 - val_loss: 1.3128 - val_accuracy: 0.6843\n",
      "Epoch 121/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9958 - accuracy: 0.7516 - val_loss: 1.3097 - val_accuracy: 0.6675\n",
      "Epoch 122/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9898 - accuracy: 0.7494 - val_loss: 1.3010 - val_accuracy: 0.6873\n",
      "Epoch 123/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9868 - accuracy: 0.7556 - val_loss: 1.3010 - val_accuracy: 0.6723\n",
      "Epoch 124/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9811 - accuracy: 0.7541 - val_loss: 1.2910 - val_accuracy: 0.6887\n",
      "Epoch 125/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9759 - accuracy: 0.7594 - val_loss: 1.2894 - val_accuracy: 0.6762\n",
      "Epoch 126/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9723 - accuracy: 0.7566 - val_loss: 1.2805 - val_accuracy: 0.6911\n",
      "Epoch 127/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9681 - accuracy: 0.7617 - val_loss: 1.2777 - val_accuracy: 0.6810\n",
      "Epoch 128/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9628 - accuracy: 0.7610 - val_loss: 1.2694 - val_accuracy: 0.6935\n",
      "Epoch 129/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9598 - accuracy: 0.7663 - val_loss: 1.2680 - val_accuracy: 0.6824\n",
      "Epoch 130/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9548 - accuracy: 0.7628 - val_loss: 1.2580 - val_accuracy: 0.6957\n",
      "Epoch 131/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9493 - accuracy: 0.7672 - val_loss: 1.2581 - val_accuracy: 0.6859\n",
      "Epoch 132/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.9465 - accuracy: 0.7639 - val_loss: 1.2537 - val_accuracy: 0.6969\n",
      "Epoch 133/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.9421 - accuracy: 0.7690 - val_loss: 1.2460 - val_accuracy: 0.6906\n",
      "Epoch 134/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.9364 - accuracy: 0.7665 - val_loss: 1.2370 - val_accuracy: 0.6980\n",
      "Epoch 135/300\n",
      "3/3 [==============================] - 0s 42ms/step - loss: 0.9333 - accuracy: 0.7700 - val_loss: 1.2357 - val_accuracy: 0.6874\n",
      "Epoch 136/300\n",
      "3/3 [==============================] - 0s 31ms/step - loss: 0.9301 - accuracy: 0.7677 - val_loss: 1.2308 - val_accuracy: 0.6981\n",
      "Epoch 137/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9231 - accuracy: 0.7716 - val_loss: 1.2199 - val_accuracy: 0.6973\n",
      "Epoch 138/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9183 - accuracy: 0.7712 - val_loss: 1.2209 - val_accuracy: 0.7003\n",
      "Epoch 139/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9155 - accuracy: 0.7729 - val_loss: 1.2133 - val_accuracy: 0.6973\n",
      "Epoch 140/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.9128 - accuracy: 0.7713 - val_loss: 1.2139 - val_accuracy: 0.7019\n",
      "Epoch 141/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.9141 - accuracy: 0.7729 - val_loss: 1.2054 - val_accuracy: 0.7000\n",
      "Epoch 142/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.9024 - accuracy: 0.7746 - val_loss: 1.1995 - val_accuracy: 0.7016\n",
      "Epoch 143/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8985 - accuracy: 0.7754 - val_loss: 1.1941 - val_accuracy: 0.7017\n",
      "Epoch 144/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8949 - accuracy: 0.7750 - val_loss: 1.1889 - val_accuracy: 0.7015\n",
      "Epoch 145/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8929 - accuracy: 0.7773 - val_loss: 1.1918 - val_accuracy: 0.7008\n",
      "Epoch 146/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8917 - accuracy: 0.7750 - val_loss: 1.1894 - val_accuracy: 0.7031\n",
      "Epoch 147/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8890 - accuracy: 0.7779 - val_loss: 1.1781 - val_accuracy: 0.7019\n",
      "Epoch 148/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8808 - accuracy: 0.7771 - val_loss: 1.1732 - val_accuracy: 0.7041\n",
      "Epoch 149/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8771 - accuracy: 0.7780 - val_loss: 1.1734 - val_accuracy: 0.7030\n",
      "Epoch 150/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8740 - accuracy: 0.7778 - val_loss: 1.1642 - val_accuracy: 0.7051\n",
      "Epoch 151/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.8709 - accuracy: 0.7782 - val_loss: 1.1686 - val_accuracy: 0.7030\n",
      "Epoch 152/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8710 - accuracy: 0.7784 - val_loss: 1.1575 - val_accuracy: 0.7076\n",
      "Epoch 153/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8673 - accuracy: 0.7802 - val_loss: 1.1637 - val_accuracy: 0.7043\n",
      "Epoch 154/300\n",
      "3/3 [==============================] - 0s 30ms/step - loss: 0.8635 - accuracy: 0.7795 - val_loss: 1.1487 - val_accuracy: 0.7081\n",
      "Epoch 155/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8598 - accuracy: 0.7806 - val_loss: 1.1470 - val_accuracy: 0.7069\n",
      "Epoch 156/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8552 - accuracy: 0.7808 - val_loss: 1.1431 - val_accuracy: 0.7094\n",
      "Epoch 157/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8524 - accuracy: 0.7807 - val_loss: 1.1351 - val_accuracy: 0.7100\n",
      "Epoch 158/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8505 - accuracy: 0.7824 - val_loss: 1.1409 - val_accuracy: 0.7095\n",
      "Epoch 159/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8517 - accuracy: 0.7806 - val_loss: 1.1482 - val_accuracy: 0.7083\n",
      "Epoch 160/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8524 - accuracy: 0.7820 - val_loss: 1.1383 - val_accuracy: 0.7100\n",
      "Epoch 161/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8419 - accuracy: 0.7830 - val_loss: 1.1287 - val_accuracy: 0.7115\n",
      "Epoch 162/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8394 - accuracy: 0.7838 - val_loss: 1.1257 - val_accuracy: 0.7125\n",
      "Epoch 163/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.8372 - accuracy: 0.7841 - val_loss: 1.1217 - val_accuracy: 0.7128\n",
      "Epoch 164/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8354 - accuracy: 0.7847 - val_loss: 1.1231 - val_accuracy: 0.7142\n",
      "Epoch 165/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8322 - accuracy: 0.7850 - val_loss: 1.1181 - val_accuracy: 0.7143\n",
      "Epoch 166/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.8301 - accuracy: 0.7849 - val_loss: 1.1154 - val_accuracy: 0.7148\n",
      "Epoch 167/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8307 - accuracy: 0.7849 - val_loss: 1.1336 - val_accuracy: 0.7121\n",
      "Epoch 168/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8311 - accuracy: 0.7842 - val_loss: 1.1100 - val_accuracy: 0.7153\n",
      "Epoch 169/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8244 - accuracy: 0.7862 - val_loss: 1.1082 - val_accuracy: 0.7164\n",
      "Epoch 170/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.8213 - accuracy: 0.7865 - val_loss: 1.1078 - val_accuracy: 0.7157\n",
      "Epoch 171/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8200 - accuracy: 0.7871 - val_loss: 1.1040 - val_accuracy: 0.7153\n",
      "Epoch 172/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.8185 - accuracy: 0.7865 - val_loss: 1.0994 - val_accuracy: 0.7170\n",
      "Epoch 173/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8152 - accuracy: 0.7876 - val_loss: 1.1004 - val_accuracy: 0.7171\n",
      "Epoch 174/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8149 - accuracy: 0.7869 - val_loss: 1.1012 - val_accuracy: 0.7147\n",
      "Epoch 175/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8202 - accuracy: 0.7847 - val_loss: 1.0946 - val_accuracy: 0.7179\n",
      "Epoch 176/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.8099 - accuracy: 0.7884 - val_loss: 1.0960 - val_accuracy: 0.7172\n",
      "Epoch 177/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8081 - accuracy: 0.7885 - val_loss: 1.0899 - val_accuracy: 0.7188\n",
      "Epoch 178/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.8064 - accuracy: 0.7875 - val_loss: 1.0910 - val_accuracy: 0.7178\n",
      "Epoch 179/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8053 - accuracy: 0.7890 - val_loss: 1.0848 - val_accuracy: 0.7195\n",
      "Epoch 180/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8024 - accuracy: 0.7902 - val_loss: 1.0807 - val_accuracy: 0.7213\n",
      "Epoch 181/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8005 - accuracy: 0.7915 - val_loss: 1.0822 - val_accuracy: 0.7214\n",
      "Epoch 182/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7985 - accuracy: 0.7919 - val_loss: 1.0863 - val_accuracy: 0.7224\n",
      "Epoch 183/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7997 - accuracy: 0.7912 - val_loss: 1.0863 - val_accuracy: 0.7151\n",
      "Epoch 184/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.8113 - accuracy: 0.7879 - val_loss: 1.0765 - val_accuracy: 0.7209\n",
      "Epoch 185/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7944 - accuracy: 0.7927 - val_loss: 1.0751 - val_accuracy: 0.7227\n",
      "Epoch 186/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7925 - accuracy: 0.7932 - val_loss: 1.0782 - val_accuracy: 0.7231\n",
      "Epoch 187/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7911 - accuracy: 0.7930 - val_loss: 1.0767 - val_accuracy: 0.7233\n",
      "Epoch 188/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7896 - accuracy: 0.7936 - val_loss: 1.0802 - val_accuracy: 0.7230\n",
      "Epoch 189/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7890 - accuracy: 0.7934 - val_loss: 1.0746 - val_accuracy: 0.7229\n",
      "Epoch 190/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7883 - accuracy: 0.7936 - val_loss: 1.0719 - val_accuracy: 0.7233\n",
      "Epoch 191/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7856 - accuracy: 0.7941 - val_loss: 1.0627 - val_accuracy: 0.7240\n",
      "Epoch 192/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7851 - accuracy: 0.7936 - val_loss: 1.0746 - val_accuracy: 0.7233\n",
      "Epoch 193/300\n",
      "3/3 [==============================] - 0s 32ms/step - loss: 0.7830 - accuracy: 0.7945 - val_loss: 1.0620 - val_accuracy: 0.7245\n",
      "Epoch 194/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7817 - accuracy: 0.7945 - val_loss: 1.0728 - val_accuracy: 0.7232\n",
      "Epoch 195/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7817 - accuracy: 0.7942 - val_loss: 1.0589 - val_accuracy: 0.7245\n",
      "Epoch 196/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7811 - accuracy: 0.7948 - val_loss: 1.0675 - val_accuracy: 0.7244\n",
      "Epoch 197/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7770 - accuracy: 0.7953 - val_loss: 1.0576 - val_accuracy: 0.7245\n",
      "Epoch 198/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7766 - accuracy: 0.7950 - val_loss: 1.0640 - val_accuracy: 0.7256\n",
      "Epoch 199/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7751 - accuracy: 0.7949 - val_loss: 1.0577 - val_accuracy: 0.7255\n",
      "Epoch 200/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7746 - accuracy: 0.7955 - val_loss: 1.0702 - val_accuracy: 0.7250\n",
      "Epoch 201/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7727 - accuracy: 0.7959 - val_loss: 1.0476 - val_accuracy: 0.7256\n",
      "Epoch 202/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7726 - accuracy: 0.7959 - val_loss: 1.0653 - val_accuracy: 0.7256\n",
      "Epoch 203/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7711 - accuracy: 0.7965 - val_loss: 1.0454 - val_accuracy: 0.7263\n",
      "Epoch 204/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.7680 - accuracy: 0.7969 - val_loss: 1.0478 - val_accuracy: 0.7260\n",
      "Epoch 205/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7658 - accuracy: 0.7973 - val_loss: 1.0475 - val_accuracy: 0.7266\n",
      "Epoch 206/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7646 - accuracy: 0.7981 - val_loss: 1.0395 - val_accuracy: 0.7277\n",
      "Epoch 207/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7694 - accuracy: 0.7962 - val_loss: 1.1038 - val_accuracy: 0.7211\n",
      "Epoch 208/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7731 - accuracy: 0.7947 - val_loss: 1.0402 - val_accuracy: 0.7273\n",
      "Epoch 209/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7612 - accuracy: 0.7983 - val_loss: 1.0399 - val_accuracy: 0.7279\n",
      "Epoch 210/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7599 - accuracy: 0.7987 - val_loss: 1.0389 - val_accuracy: 0.7279\n",
      "Epoch 211/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7588 - accuracy: 0.7990 - val_loss: 1.0353 - val_accuracy: 0.7280\n",
      "Epoch 212/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7577 - accuracy: 0.7989 - val_loss: 1.0395 - val_accuracy: 0.7292\n",
      "Epoch 213/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7566 - accuracy: 0.7994 - val_loss: 1.0334 - val_accuracy: 0.7296\n",
      "Epoch 214/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7574 - accuracy: 0.7989 - val_loss: 1.0392 - val_accuracy: 0.7295\n",
      "Epoch 215/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7553 - accuracy: 0.7996 - val_loss: 1.0344 - val_accuracy: 0.7304\n",
      "Epoch 216/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7538 - accuracy: 0.8004 - val_loss: 1.0300 - val_accuracy: 0.7318\n",
      "Epoch 217/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7538 - accuracy: 0.7999 - val_loss: 1.0339 - val_accuracy: 0.7311\n",
      "Epoch 218/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7516 - accuracy: 0.8009 - val_loss: 1.0289 - val_accuracy: 0.7320\n",
      "Epoch 219/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7508 - accuracy: 0.8008 - val_loss: 1.0377 - val_accuracy: 0.7306\n",
      "Epoch 220/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7495 - accuracy: 0.8012 - val_loss: 1.0311 - val_accuracy: 0.7328\n",
      "Epoch 221/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7502 - accuracy: 0.8005 - val_loss: 1.0227 - val_accuracy: 0.7318\n",
      "Epoch 222/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7463 - accuracy: 0.8021 - val_loss: 1.0239 - val_accuracy: 0.7326\n",
      "Epoch 223/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7450 - accuracy: 0.8027 - val_loss: 1.0211 - val_accuracy: 0.7326\n",
      "Epoch 224/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7455 - accuracy: 0.8026 - val_loss: 1.0375 - val_accuracy: 0.7305\n",
      "Epoch 225/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7467 - accuracy: 0.8014 - val_loss: 1.0249 - val_accuracy: 0.7333\n",
      "Epoch 226/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7447 - accuracy: 0.8028 - val_loss: 1.0272 - val_accuracy: 0.7325\n",
      "Epoch 227/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7415 - accuracy: 0.8027 - val_loss: 1.0201 - val_accuracy: 0.7344\n",
      "Epoch 228/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7412 - accuracy: 0.8033 - val_loss: 1.0153 - val_accuracy: 0.7346\n",
      "Epoch 229/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7393 - accuracy: 0.8046 - val_loss: 1.0281 - val_accuracy: 0.7345\n",
      "Epoch 230/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7392 - accuracy: 0.8041 - val_loss: 1.0125 - val_accuracy: 0.7358\n",
      "Epoch 231/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7368 - accuracy: 0.8053 - val_loss: 1.0222 - val_accuracy: 0.7355\n",
      "Epoch 232/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7380 - accuracy: 0.8040 - val_loss: 1.0176 - val_accuracy: 0.7337\n",
      "Epoch 233/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7396 - accuracy: 0.8032 - val_loss: 1.0191 - val_accuracy: 0.7356\n",
      "Epoch 234/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7346 - accuracy: 0.8055 - val_loss: 1.0101 - val_accuracy: 0.7373\n",
      "Epoch 235/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7331 - accuracy: 0.8060 - val_loss: 1.0115 - val_accuracy: 0.7373\n",
      "Epoch 236/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7336 - accuracy: 0.8050 - val_loss: 1.0137 - val_accuracy: 0.7354\n",
      "Epoch 237/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7339 - accuracy: 0.8044 - val_loss: 1.0084 - val_accuracy: 0.7366\n",
      "Epoch 238/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7302 - accuracy: 0.8063 - val_loss: 1.0078 - val_accuracy: 0.7372\n",
      "Epoch 239/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7290 - accuracy: 0.8067 - val_loss: 1.0122 - val_accuracy: 0.7374\n",
      "Epoch 240/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7296 - accuracy: 0.8057 - val_loss: 1.0053 - val_accuracy: 0.7374\n",
      "Epoch 241/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7289 - accuracy: 0.8056 - val_loss: 1.0062 - val_accuracy: 0.7377\n",
      "Epoch 242/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7303 - accuracy: 0.8063 - val_loss: 1.0284 - val_accuracy: 0.7357\n",
      "Epoch 243/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7291 - accuracy: 0.8050 - val_loss: 1.0024 - val_accuracy: 0.7388\n",
      "Epoch 244/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7244 - accuracy: 0.8074 - val_loss: 1.0046 - val_accuracy: 0.7378\n",
      "Epoch 245/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7244 - accuracy: 0.8067 - val_loss: 1.0021 - val_accuracy: 0.7374\n",
      "Epoch 246/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7238 - accuracy: 0.8070 - val_loss: 1.0020 - val_accuracy: 0.7369\n",
      "Epoch 247/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7235 - accuracy: 0.8066 - val_loss: 0.9995 - val_accuracy: 0.7382\n",
      "Epoch 248/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7232 - accuracy: 0.8072 - val_loss: 1.0049 - val_accuracy: 0.7371\n",
      "Epoch 249/300\n",
      "3/3 [==============================] - 0s 40ms/step - loss: 0.7204 - accuracy: 0.8079 - val_loss: 0.9969 - val_accuracy: 0.7387\n",
      "Epoch 250/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7207 - accuracy: 0.8072 - val_loss: 1.0024 - val_accuracy: 0.7379\n",
      "Epoch 251/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7184 - accuracy: 0.8082 - val_loss: 0.9972 - val_accuracy: 0.7400\n",
      "Epoch 252/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7186 - accuracy: 0.8077 - val_loss: 0.9995 - val_accuracy: 0.7371\n",
      "Epoch 253/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7196 - accuracy: 0.8082 - val_loss: 0.9995 - val_accuracy: 0.7384\n",
      "Epoch 254/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7168 - accuracy: 0.8088 - val_loss: 0.9900 - val_accuracy: 0.7391\n",
      "Epoch 255/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7166 - accuracy: 0.8086 - val_loss: 1.0011 - val_accuracy: 0.7382\n",
      "Epoch 256/300\n",
      "3/3 [==============================] - 0s 33ms/step - loss: 0.7151 - accuracy: 0.8081 - val_loss: 0.9881 - val_accuracy: 0.7407\n",
      "Epoch 257/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7141 - accuracy: 0.8089 - val_loss: 0.9950 - val_accuracy: 0.7401\n",
      "Epoch 258/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7140 - accuracy: 0.8081 - val_loss: 1.0037 - val_accuracy: 0.7373\n",
      "Epoch 259/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7155 - accuracy: 0.8076 - val_loss: 0.9936 - val_accuracy: 0.7404\n",
      "Epoch 260/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7117 - accuracy: 0.8092 - val_loss: 0.9884 - val_accuracy: 0.7402\n",
      "Epoch 261/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7112 - accuracy: 0.8094 - val_loss: 0.9938 - val_accuracy: 0.7404\n",
      "Epoch 262/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7112 - accuracy: 0.8097 - val_loss: 0.9877 - val_accuracy: 0.7410\n",
      "Epoch 263/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7118 - accuracy: 0.8094 - val_loss: 0.9904 - val_accuracy: 0.7399\n",
      "Epoch 264/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7076 - accuracy: 0.8101 - val_loss: 0.9866 - val_accuracy: 0.7409\n",
      "Epoch 265/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7076 - accuracy: 0.8103 - val_loss: 1.0005 - val_accuracy: 0.7379\n",
      "Epoch 266/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7095 - accuracy: 0.8104 - val_loss: 0.9945 - val_accuracy: 0.7419\n",
      "Epoch 267/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.7085 - accuracy: 0.8102 - val_loss: 0.9858 - val_accuracy: 0.7416\n",
      "Epoch 268/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.7058 - accuracy: 0.8102 - val_loss: 0.9862 - val_accuracy: 0.7431\n",
      "Epoch 269/300\n",
      "3/3 [==============================] - 0s 39ms/step - loss: 0.7048 - accuracy: 0.8108 - val_loss: 0.9838 - val_accuracy: 0.7424\n",
      "Epoch 270/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.7049 - accuracy: 0.8110 - val_loss: 0.9894 - val_accuracy: 0.7420\n",
      "Epoch 271/300\n",
      "3/3 [==============================] - 0s 35ms/step - loss: 0.7036 - accuracy: 0.8110 - val_loss: 0.9791 - val_accuracy: 0.7435\n",
      "Epoch 272/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.7028 - accuracy: 0.8111 - val_loss: 0.9836 - val_accuracy: 0.7426\n",
      "Epoch 273/300\n",
      "3/3 [==============================] - 0s 37ms/step - loss: 0.7015 - accuracy: 0.8116 - val_loss: 0.9998 - val_accuracy: 0.7430\n",
      "Epoch 274/300\n",
      "3/3 [==============================] - 0s 28ms/step - loss: 0.7051 - accuracy: 0.8107 - val_loss: 0.9810 - val_accuracy: 0.7447\n",
      "Epoch 275/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6998 - accuracy: 0.8125 - val_loss: 0.9794 - val_accuracy: 0.7448\n",
      "Epoch 276/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.7002 - accuracy: 0.8115 - val_loss: 0.9945 - val_accuracy: 0.7433\n",
      "Epoch 277/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6992 - accuracy: 0.8122 - val_loss: 0.9771 - val_accuracy: 0.7444\n",
      "Epoch 278/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6973 - accuracy: 0.8128 - val_loss: 0.9810 - val_accuracy: 0.7454\n",
      "Epoch 279/300\n",
      "3/3 [==============================] - 0s 25ms/step - loss: 0.6980 - accuracy: 0.8126 - val_loss: 0.9861 - val_accuracy: 0.7450\n",
      "Epoch 280/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6984 - accuracy: 0.8124 - val_loss: 0.9778 - val_accuracy: 0.7439\n",
      "Epoch 281/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6960 - accuracy: 0.8132 - val_loss: 0.9760 - val_accuracy: 0.7456\n",
      "Epoch 282/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6950 - accuracy: 0.8132 - val_loss: 0.9853 - val_accuracy: 0.7441\n",
      "Epoch 283/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6958 - accuracy: 0.8135 - val_loss: 0.9723 - val_accuracy: 0.7462\n",
      "Epoch 284/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6950 - accuracy: 0.8132 - val_loss: 0.9749 - val_accuracy: 0.7455\n",
      "Epoch 285/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6943 - accuracy: 0.8142 - val_loss: 0.9830 - val_accuracy: 0.7468\n",
      "Epoch 286/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6933 - accuracy: 0.8144 - val_loss: 0.9704 - val_accuracy: 0.7470\n",
      "Epoch 287/300\n",
      "3/3 [==============================] - 0s 23ms/step - loss: 0.6925 - accuracy: 0.8147 - val_loss: 0.9724 - val_accuracy: 0.7475\n",
      "Epoch 288/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6932 - accuracy: 0.8139 - val_loss: 0.9768 - val_accuracy: 0.7464\n",
      "Epoch 289/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6909 - accuracy: 0.8151 - val_loss: 0.9671 - val_accuracy: 0.7471\n",
      "Epoch 290/300\n",
      "3/3 [==============================] - 0s 27ms/step - loss: 0.6909 - accuracy: 0.8149 - val_loss: 0.9780 - val_accuracy: 0.7465\n",
      "Epoch 291/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6891 - accuracy: 0.8152 - val_loss: 0.9679 - val_accuracy: 0.7481\n",
      "Epoch 292/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6897 - accuracy: 0.8150 - val_loss: 0.9685 - val_accuracy: 0.7484\n",
      "Epoch 293/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6904 - accuracy: 0.8147 - val_loss: 0.9719 - val_accuracy: 0.7480\n",
      "Epoch 294/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6863 - accuracy: 0.8160 - val_loss: 0.9688 - val_accuracy: 0.7483\n",
      "Epoch 295/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6855 - accuracy: 0.8156 - val_loss: 0.9666 - val_accuracy: 0.7484\n",
      "Epoch 296/300\n",
      "3/3 [==============================] - 0s 43ms/step - loss: 0.6856 - accuracy: 0.8159 - val_loss: 0.9733 - val_accuracy: 0.7479\n",
      "Epoch 297/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6880 - accuracy: 0.8144 - val_loss: 0.9649 - val_accuracy: 0.7483\n",
      "Epoch 298/300\n",
      "3/3 [==============================] - 0s 29ms/step - loss: 0.6860 - accuracy: 0.8166 - val_loss: 0.9667 - val_accuracy: 0.7494\n",
      "Epoch 299/300\n",
      "3/3 [==============================] - 0s 24ms/step - loss: 0.6849 - accuracy: 0.8155 - val_loss: 0.9774 - val_accuracy: 0.7451\n",
      "Epoch 300/300\n",
      "3/3 [==============================] - 0s 26ms/step - loss: 0.6839 - accuracy: 0.8164 - val_loss: 0.9639 - val_accuracy: 0.7486\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<keras.src.callbacks.History at 0x7fe7706ed880>"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Define the model that will turn\n",
    "# `encoder_input_data` & `decoder_input_data` into `decoder_target_data`\n",
    "gru = Model([encoder_inputs, decoder_inputs], decoder_outputs)\n",
    "\n",
    "# Run training\n",
    "gru.compile(optimizer='rmsprop', loss='categorical_crossentropy',\n",
    "              metrics=['accuracy'])\n",
    "gru_hist = gru.fit([encoder_input_data, decoder_input_data], decoder_target_data,\n",
    "          batch_size=batch_size,\n",
    "          epochs=epochs,\n",
    "          validation_split=0.2)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "tf",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
